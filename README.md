## ğŸš´ ETL-Velo

Ce projet propose la mise en place dâ€™un pipeline simple pour collecter, transformer et analyser les donnÃ©es des systÃ¨mes de vÃ©los en libre-service de Paris, Nantes, Toulouse et Strasbourg.
Les donnÃ©es sont stockÃ©es dans MinIO (data lake), transformÃ©es Ã  lâ€™aide de DBT (Data Build Tool) pour assurer la qualitÃ©, la modularitÃ© et la traÃ§abilitÃ© des modÃ¨les de donnÃ©es, puis consolidÃ©es dans DuckDB (data warehouse). Enfin, elles sont prÃ©sentÃ©es via Streamlit pour faciliter lâ€™exploration et la visualisation des rÃ©sultats.

---

## ğŸ“¥ **Sources des DonnÃ©es**

- [API Paris](https://opendata.paris.fr/explore/dataset/velib-disponibilite-en-temps-reel/api/)  
- [API Nantes](https://data.nantesmetropole.fr/explore/dataset/244400404_stations-velos-libre-service-nantes-metropole-disponibilites/api/)  
- [API Toulouse](https://data.toulouse-metropole.fr/explore/dataset/api-velo-toulouse-temps-reel/api/)  
- [API Strasbourg](https://data.strasbourg.eu/explore/dataset/stations-velhop/api/)  
- [API Open Data Communes](https://geo.api.gouv.fr/communes)  

---

## ğŸ—‚ï¸ **Structure du Projet**

```plaintext
â”œâ”€â”€ data/                      # DonnÃ©es utilisÃ©es par les processus
â”‚   â””â”€â”€ duckdb/                # Base de donnÃ©es locale DuckDB
â”œâ”€â”€ src/                       # Code source principal
â”‚   â”œâ”€â”€ elt/                   # Projet DBT pour la transformation des donnÃ©es
â”‚   â”œâ”€â”€ sql_statements/        # RequÃªtes SQL rÃ©utilisables
â”‚   â”œâ”€â”€ data_ingestion.py      # Ingestion des donnÃ©es en temps rÃ©el
â”‚   â”œâ”€â”€ data_transformation.py # Transformation des donnÃ©es brutes
â”‚   â”œâ”€â”€ init_db.py             # Fichier d'initialisation de la base de donnÃ©es
â”‚   â””â”€â”€ ui.py                  # Interface utilisateur
â”œâ”€â”€ docker-compose.yml         # Orchestration Docker Compose
â”œâ”€â”€ Dockerfile                 # Configuration Docker
â”œâ”€â”€ poetry.lock                # Verrouillage des dÃ©pendances Poetry
â”œâ”€â”€ pyproject.toml             # Configuration du projet Poetry
â””â”€â”€ README.md                  # Documentation du projet
```

---

## âš™ï¸ **Workflow du Projet**

### **1. Ingestion des donnÃ©es**
**Objectif** : RÃ©cupÃ©rer des donnÃ©es brutes depuis des sources externes.
#### Ã‰tapes : 
Dans le fichier Python `data_ingestion.py`
- **`get_realtime_bicycle_data`** : 
  - RÃ©cupÃ¨re les donnÃ©es en temps rÃ©el sur les vÃ©los disponibles des villes (Paris, Nantes, Toulouse, Strasbourg).
- **`get_commune_data`** : 
  - RÃ©cupÃ¨re des donnÃ©es sur les communes.

#### Produits :
- Les donnÃ©es brutes sont enregistrÃ©es dans les fichiers Parquet dans le bucket dÃ©diÃ©.



### **2. Transformation des donnÃ©es avec DBT**  
**Objectif** : Organiser, nettoyer et structurer les donnÃ©es brutes issues du data lake pour les rendre exploitables.

#### Ã‰tapes :  
La transformation des donnÃ©es est orchestrÃ©e via **DBT**, selon une architecture modulaire :

- ğŸ“ **Staging**  
  - CrÃ©ation de tables temporaires Ã  partir des fichiers bruts stockÃ©s dans **MinIO**.  
  - Ces modÃ¨les permettent de normaliser les formats et de prÃ©parer les donnÃ©es pour les Ã©tapes suivantes.

- ğŸ“ **Consolidate**  
  - Construction de tables consolidÃ©es, alimentÃ©es en **mode incrÃ©mental**, pour intÃ©grer les nouvelles donnÃ©es sans retraiter lâ€™ensemble du dataset.  
  - Les donnÃ©es des communes et des stations sont nettoyÃ©es, enrichies et structurÃ©es pour lâ€™analyse.

#### Produits :  
- Les tables consolidÃ©es sont stockÃ©es dans **DuckDB** et servent de base aux modÃ¨les analytiques et aux vues agrÃ©gÃ©es.

---

### **3. ModÃ©lisation analytique et agrÃ©gation**  
**Objectif** : SynthÃ©tiser les donnÃ©es consolidÃ©es pour produire des modÃ¨les analytiques et des vues prÃªtes Ã  lâ€™exploration.

#### Ã‰tapes :  
La modÃ©lisation suit une logique en Ã©toile et se dÃ©compose en deux niveaux :

- ğŸ“ **Star_model**  
  - CrÃ©ation des **tables dimensionnelles** (ex. : `dim_city`, `dim_station`) et de la **table factuelle** (`fact_station_statement`) en associant les donnÃ©es consolidÃ©es.  
  - Ces modÃ¨les facilitent les jointures et les analyses multi-axes.

- ğŸ“ **Analytics**  
  - GÃ©nÃ©ration de **vues analytiques** prÃªtes Ã  Ãªtre exposÃ©es dans **Streamlit**.  
  - Ces vues permettent dâ€™explorer les mÃ©triques clÃ©s et les tendances du systÃ¨me de vÃ©los en libre-service.

#### Produits :  
- Les vues finales sont stockÃ©es dans **DuckDB** et intÃ©grÃ©es Ã  lâ€™interface Streamlit pour la visualisation interactive.

---

## ğŸš€ **Installation et ExÃ©cution**

1. **Cloner le dÃ©pÃ´t :**  
   ```bash
   git clone https://github.com/BrightMehou/etl-velo.git
   cd etl-velo
   ```

2. **Installer Docker** : 
   Si Docker n'est pas encore installÃ© : [Docker installation](https://www.docker.com/)

3. **Construire les images Docker et lancer les containeurs :**  
   ```bash
   docker-compose up -d
   ```

4. **AccÃ©der Ã  l'interface streamlit :**  
   Rendez-vous sur [http://localhost:8501](http://localhost:8501) 

---

## ğŸ“Š **Analyse des donnÃ©es**


Vous devriez obtenir les rÃ©sultats des requÃªtes suivantes.

#### 1. Nombre d'emplacements disponibles pour les vÃ©los dans une ville :
```sql
SELECT dm.NAME, tmp.SUM_BICYCLE_DOCKS_AVAILABLE
FROM DIM_CITY dm
INNER JOIN (
    SELECT CITY_ID, SUM(BICYCLE_DOCKS_AVAILABLE) AS SUM_BICYCLE_DOCKS_AVAILABLE
    FROM FACT_STATION_STATEMENT
    WHERE CREATED_DATE = (SELECT MAX(CREATED_DATE) FROM CONSOLIDATE_STATION)
    GROUP BY CITY_ID
) tmp ON dm.ID = tmp.CITY_ID
WHERE lower(dm.NAME) IN ('paris', 'nantes', 'strasbourg', 'toulouse');
```

#### 2. Moyenne des vÃ©los disponibles par station :
```sql
SELECT ds.NAME, ds.CODE, ds.ADDRESS, tmp.AVG_DOCK_AVAILABLE
FROM DIM_STATION ds
JOIN (
    SELECT STATION_ID, AVG(BICYCLE_AVAILABLE) AS AVG_DOCK_AVAILABLE
    FROM FACT_STATION_STATEMENT
    GROUP BY STATION_ID
) tmp ON ds.ID = tmp.STATION_ID;
```